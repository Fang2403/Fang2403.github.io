# Reflection on Project 2

## Our work

The consumption of online news is expediting day by day due to the extensive adoption of smartphones and the rise of social networks. Online news can capture the eye of a signiﬁcant amount of Internet users within a brief period of your time. Prediction of online news popularity helps news organizations to gain better insights into the audience interests and to deliver more relevant and appealing content in a proactive manner. The company can allocate resources more wisely to prepare stories over their life cycle. Moreover, prediction of news popularity is also beneﬁcial for trend forecasting, understanding the collective human behavior, advertisers to propose more proﬁtable monetization techniques,and readers to ﬁlter the huge amount of information quickly and efﬁciently.

In this project we analyze and predict the number of shares within different data channel of interest using an online news data set from [Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Online+News+Popularity#). This data set summarizes a heterogeneous set of features about articles published by Mashable in a period of two years.
   
## Most difficult part

The most difficult and time-consuming part for me is to figure out how to automating documents via 'params'. There seems be an additional list layer on my parameter, so it took me lots of time to figure out how to correctly render the documents.
The second hard part is to show images properly in the documents. Because full path of images are created cutomatically in the output file, there are some issues for .rm file to load the images correctly. At first, I fixed the path to relative path manually. Finally we specified subfolder for each documents to solve the problem. 

## Take-away from this project

The big take-away from this project is the experience in automating documents and building model via 'caret' packages. I think 'caret' package is so amazing, we don't need to use different functions from multiple packages to build various models. We just need one function 'train' now. The same syntax saves me lots of time and brain memory. We can put cross validation, trainControl and preProcessing in it as well, which simplify our code a lot.    

## In the future

I decided to learn more about GitHub before starting my next project. As Github is such an amazing and useful tools to collaborate and track our work, I hope to use it more efficient in the future. 

[Link to GitHub page](https://jahinic.github.io/ST558_Project2/)

[Link to repo](https://github.com/jahinic/ST558_Project2)

